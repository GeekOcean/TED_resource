1
00:00:13,335 --> 00:00:17,041
So a friend of mine was riding in a taxi to the airport the other day,

2
00:00:17,065 --> 00:00:19,775
and on the way, she was chatting with the taxi driver,

3
00:00:19,799 --> 00:00:22,228
and he said to her, with total sincerity,

4
00:00:22,252 --> 00:00:25,538
"I can tell you are a really good person."

5
00:00:25,562 --> 00:00:27,379
And when she told me this story later,

6
00:00:27,403 --> 00:00:30,578
she said she couldn't believe how good it made her feel,

7
00:00:30,602 --> 00:00:32,661
that it meant a lot to her.

8
00:00:32,685 --> 00:00:35,711
Now that may seem like a strong reaction from my friend

9
00:00:35,735 --> 00:00:37,939
to the words of a total stranger,

10
00:00:37,963 --> 00:00:39,581
but she's not alone.

11
00:00:39,605 --> 00:00:40,970
I'm a social scientist.

12
00:00:40,994 --> 00:00:43,647
I study the psychology of good people,

13
00:00:43,671 --> 00:00:47,961
and research in my field says many of us care deeply

14
00:00:47,985 --> 00:00:52,986
about feeling like a good person and being seen as a good person.

15
00:00:53,287 --> 00:00:58,120
Now, your definition of "good person" and your definition of "good person"

16
00:00:58,144 --> 00:01:00,884
and maybe the taxi driver's definition of "good person" --

17
00:01:00,908 --> 00:01:02,891
we may not all have the same definition,

18
00:01:02,915 --> 00:01:05,740
but within whatever our definition is,

19
00:01:05,764 --> 00:01:08,565
that moral identity is important to many of us.

20
00:01:08,974 --> 00:01:14,195
Now, if somebody challenges it, like they question us for a joke we tell,

21
00:01:14,219 --> 00:01:16,902
or maybe we say our workforce is homogenous,

22
00:01:16,926 --> 00:01:19,905
or a slippery business expense,

23
00:01:19,929 --> 00:01:23,127
we go into red-zone defensiveness a lot of the time.

24
00:01:23,151 --> 00:01:26,242
I mean, sometimes we call out

25
00:01:26,266 --> 00:01:29,935
all the ways in which we help people from marginalized groups,

26
00:01:29,959 --> 00:01:31,727
or we donate to charity,

27
00:01:31,751 --> 00:01:35,790
or the hours we volunteer to nonprofits.

28
00:01:35,814 --> 00:01:39,505
We work to protect that good person identity.

29
00:01:39,529 --> 00:01:41,465
It's important to many of us.

30
00:01:42,337 --> 00:01:44,195
But what if I told you this?

31
00:01:44,219 --> 00:01:48,933
What if I told you that our attachment to being good people

32
00:01:48,957 --> 00:01:51,473
is getting in the way of us being better people?

33
00:01:52,045 --> 00:01:58,371
What if I told you that our definition of "good person" is so narrow,

34
00:01:58,395 --> 00:02:00,926
it's scientifically impossible to meet?

35
00:02:01,626 --> 00:02:04,903
And what if I told you the path to being better people

36
00:02:04,927 --> 00:02:07,863
just begins with letting go of being a good person?

37
00:02:08,696 --> 00:02:11,336
Now, let me tell you a little bit about the research

38
00:02:11,360 --> 00:02:12,832
about how the human mind works

39
00:02:12,856 --> 00:02:14,006
to explain.

40
00:02:14,360 --> 00:02:18,468
The brain relies on shortcuts to do a lot of its work.

41
00:02:18,492 --> 00:02:20,117
That means a lot of the time,

42
00:02:20,141 --> 00:02:23,469
your mental processes are taking place outside of your awareness,

43
00:02:23,493 --> 00:02:28,231
like in low-battery, low-power mode in the back of your mind.

44
00:02:28,908 --> 00:02:32,369
That's, in fact, the premise of bounded rationality.

45
00:02:32,393 --> 00:02:35,834
Bounded rationality is the Nobel Prize-winning idea

46
00:02:35,858 --> 00:02:38,700
that the human mind has limited storage resources,

47
00:02:38,724 --> 00:02:40,820
limited processing power,

48
00:02:40,844 --> 00:02:44,876
and as a result, it relies on shortcuts to do a lot of its work.

49
00:02:45,391 --> 00:02:46,915
So for example,

50
00:02:47,653 --> 00:02:50,287
some scientists estimate that in any given moment ...

51
00:02:51,090 --> 00:02:53,170
Better, better click, right? There we go.

52
00:02:53,194 --> 00:02:54,201
(Laughter)

53
00:02:54,225 --> 00:02:55,469
At any given moment,

54
00:02:55,493 --> 00:02:59,297
11 million pieces of information are coming into your mind.

55
00:02:59,874 --> 00:03:01,490
Eleven million.

56
00:03:01,514 --> 00:03:04,387
And only 40 of them are being processed consciously.

57
00:03:04,871 --> 00:03:07,093
So 11 million, 40.

58
00:03:07,960 --> 00:03:09,844
I mean, has this ever happened to you?

59
00:03:09,868 --> 00:03:12,222
Have you ever had a really busy day at work,

60
00:03:12,246 --> 00:03:13,975
and you drive home,

61
00:03:13,999 --> 00:03:16,217
and when you get in the door,

62
00:03:16,241 --> 00:03:19,489
you realize you don't even remember the drive home,

63
00:03:19,513 --> 00:03:22,016
like whether you had green lights or red lights.

64
00:03:22,040 --> 00:03:24,450
You don't even remember. You were on autopilot.

65
00:03:24,794 --> 00:03:28,081
Or have you ever opened the fridge,

66
00:03:28,105 --> 00:03:30,177
looked for the butter,

67
00:03:30,201 --> 00:03:33,145
swore there is no butter,

68
00:03:33,169 --> 00:03:36,786
and then realized the butter was right in front of you the whole time?

69
00:03:36,810 --> 00:03:40,331
These are the kinds of "whoops" moments that make us giggle,

70
00:03:40,355 --> 00:03:42,366
and this is what happens in a brain

71
00:03:42,390 --> 00:03:45,964
that can handle 11 million pieces of information coming in

72
00:03:45,988 --> 00:03:48,565
with only 40 being processed consciously.

73
00:03:48,589 --> 00:03:51,969
That's the bounded part of bounded rationality.

74
00:03:55,172 --> 00:03:57,649
This work on bounded rationality

75
00:03:57,673 --> 00:04:01,839
is what's inspired work I've done with my collaborators

76
00:04:01,863 --> 00:04:04,498
Max Bazerman and Mahzarin Banaji,

77
00:04:04,522 --> 00:04:07,168
on what we call bounded ethicality.

78
00:04:07,522 --> 00:04:10,594
So it's the same premise as bounded rationality,

79
00:04:10,618 --> 00:04:16,219
that we have a human mind that is bounded in some sort of way

80
00:04:16,243 --> 00:04:18,325
and relying on shortcuts,

81
00:04:18,349 --> 00:04:22,174
and that those shortcuts can sometimes lead us astray.

82
00:04:22,706 --> 00:04:24,231
With bounded rationality,

83
00:04:24,255 --> 00:04:27,941
perhaps it affects the cereal we buy in the grocery store,

84
00:04:27,965 --> 00:04:31,048
or the product we launch in the boardroom.

85
00:04:31,656 --> 00:04:34,339
With bounded ethicality, the human mind,

86
00:04:34,363 --> 00:04:36,442
the same human mind,

87
00:04:36,466 --> 00:04:37,958
is making decisions,

88
00:04:37,982 --> 00:04:40,768
and here, it's about who to hire next,

89
00:04:40,792 --> 00:04:42,442
or what joke to tell

90
00:04:42,466 --> 00:04:44,688
or that slippery business decision.

91
00:04:45,977 --> 00:04:50,580
So let me give you an example of bounded ethicality at work.

92
00:04:50,604 --> 00:04:53,390
Unconscious bias is one place

93
00:04:53,414 --> 00:04:56,923
where we see the effects of bounded ethicality.

94
00:04:56,947 --> 00:05:01,333
So unconscious bias refers to associations we have in our mind,

95
00:05:01,357 --> 00:05:05,647
the shortcuts your brain is using to organize information,

96
00:05:05,671 --> 00:05:07,935
very likely outside of your awareness,

97
00:05:07,959 --> 00:05:11,411
not necessarily lining up with your conscious beliefs.

98
00:05:12,323 --> 00:05:14,847
Researchers Nosek, Banaji and Greenwald

99
00:05:14,871 --> 00:05:17,602
have looked at data from millions of people,

100
00:05:17,626 --> 00:05:20,383
and what they've found is, for example,

101
00:05:20,407 --> 00:05:23,900
most white Americans can more quickly and easily

102
00:05:23,924 --> 00:05:28,193
associate white people and good things

103
00:05:28,217 --> 00:05:30,510
than black people and good things,

104
00:05:31,470 --> 00:05:37,084
and most men and women can more quickly and easily associate

105
00:05:37,108 --> 00:05:41,410
men and science than women and science.

106
00:05:41,957 --> 00:05:46,244
And these associations don't necessarily line up

107
00:05:46,268 --> 00:05:48,143
with what people consciously think.

108
00:05:48,167 --> 00:05:51,500
They may have very egalitarian views, in fact.

109
00:05:52,026 --> 00:05:56,439
So sometimes, that 11 million and that 40 just don't line up.

110
00:05:57,222 --> 00:05:59,189
And here's another example:

111
00:05:59,213 --> 00:06:00,705
conflicts of interest.

112
00:06:01,192 --> 00:06:05,002
So we tend to underestimate how much a small gift --

113
00:06:05,026 --> 00:06:08,669
imagine a ballpoint pen or dinner --

114
00:06:08,693 --> 00:06:12,851
how much that small gift can affect our decision making.

115
00:06:13,672 --> 00:06:17,998
We don't realize that our mind is unconsciously lining up evidence

116
00:06:18,022 --> 00:06:21,553
to support the point of view of the gift-giver,

117
00:06:21,577 --> 00:06:26,398
no matter how hard we're consciously trying to be objective and professional.

118
00:06:27,509 --> 00:06:29,228
We also see bounded ethicality --

119
00:06:29,252 --> 00:06:32,629
despite our attachment to being good people,

120
00:06:32,653 --> 00:06:34,734
we still make mistakes,

121
00:06:34,758 --> 00:06:38,769
and we make mistakes that sometimes hurt other people,

122
00:06:38,793 --> 00:06:41,263
that sometimes promote injustice,

123
00:06:41,287 --> 00:06:43,312
despite our best attempts,

124
00:06:43,336 --> 00:06:47,453
and we explain away our mistakes rather than learning from them.

125
00:06:48,630 --> 00:06:51,083
Like, for example,

126
00:06:51,107 --> 00:06:54,908
when I got an email from a female student in my class

127
00:06:54,932 --> 00:06:57,480
saying that a reading I had assigned,

128
00:06:57,504 --> 00:07:00,258
a reading I had been assigning for years,

129
00:07:00,282 --> 00:07:01,713
was sexist.

130
00:07:02,558 --> 00:07:08,146
Or when I confused two students in my class

131
00:07:08,170 --> 00:07:09,527
of the same race --

132
00:07:09,551 --> 00:07:11,821
look nothing alike --

133
00:07:11,845 --> 00:07:14,004
when I confused them for each other

134
00:07:14,028 --> 00:07:16,693
more than once, in front of everybody.

135
00:07:17,705 --> 00:07:22,028
These kinds of mistakes send us, send me,

136
00:07:22,052 --> 00:07:24,887
into red-zone defensiveness.

137
00:07:24,911 --> 00:07:29,141
They leave us fighting for that good person identity.

138
00:07:30,009 --> 00:07:34,349
But the latest work that I've been doing on bounded ethicality with Mary Kern

139
00:07:34,373 --> 00:07:37,945
says that we're not only prone to mistakes --

140
00:07:37,969 --> 00:07:43,208
that tendency towards mistakes depends on how close we are to that red zone.

141
00:07:43,232 --> 00:07:47,431
So most of the time, nobody's challenging our good person identity,

142
00:07:47,455 --> 00:07:49,614
and so we're not thinking too much

143
00:07:49,638 --> 00:07:51,971
about the ethical implications of our decisions,

144
00:07:51,995 --> 00:07:55,874
and our model shows that we're then spiraling

145
00:07:55,898 --> 00:08:00,637
towards less and less ethical behavior most of the time.

146
00:08:00,661 --> 00:08:03,509
On the other hand, somebody might challenge our identity,

147
00:08:03,533 --> 00:08:07,032
or, upon reflection, we may be challenging it ourselves.

148
00:08:07,056 --> 00:08:11,180
So the ethical implications of our decisions become really salient,

149
00:08:11,204 --> 00:08:16,941
and in those cases, we spiral towards more and more good person behavior,

150
00:08:16,965 --> 00:08:18,806
or, to be more precise,

151
00:08:18,830 --> 00:08:23,368
towards more and more behavior that makes us feel like a good person,

152
00:08:23,392 --> 00:08:25,836
which isn't always the same, of course.

153
00:08:27,233 --> 00:08:30,876
The idea with bounded ethicality

154
00:08:30,900 --> 00:08:35,102
is that we are perhaps overestimating

155
00:08:35,126 --> 00:08:40,294
the importance our inner compass is playing in our ethical decisions.

156
00:08:40,318 --> 00:08:44,803
We perhaps are overestimating how much our self-interest

157
00:08:44,827 --> 00:08:48,199
is driving our decisions,

158
00:08:48,223 --> 00:08:53,938
and perhaps we don't realize how much our self-view as a good person

159
00:08:53,962 --> 00:08:56,486
is affecting our behavior,

160
00:08:56,510 --> 00:09:01,995
that in fact, we're working so hard to protect that good person identity,

161
00:09:02,019 --> 00:09:04,313
to keep out of that red zone,

162
00:09:04,337 --> 00:09:09,691
that we're not actually giving ourselves space to learn from our mistakes

163
00:09:09,715 --> 00:09:12,032
and actually be better people.

164
00:09:13,818 --> 00:09:16,859
It's perhaps because we expect it to be easy.

165
00:09:16,883 --> 00:09:20,973
We have this definition of good person that's either-or.

166
00:09:20,997 --> 00:09:24,036
Either you are a good person or you're not.

167
00:09:24,060 --> 00:09:26,680
Either you have integrity or you don't.

168
00:09:26,704 --> 00:09:31,336
Either you are a racist or a sexist or a homophobe or you're not.

169
00:09:31,360 --> 00:09:35,343
And in this either-or definition, there's no room to grow.

170
00:09:36,264 --> 00:09:37,415
And by the way,

171
00:09:37,439 --> 00:09:40,423
this is not what we do in most parts of our lives.

172
00:09:40,447 --> 00:09:42,922
Life, if you needed to learn accounting,

173
00:09:42,946 --> 00:09:44,639
you would take an accounting class,

174
00:09:44,663 --> 00:09:46,957
or if you become a parent,

175
00:09:46,981 --> 00:09:50,488
we pick up a book and we read about it.

176
00:09:50,512 --> 00:09:53,139
We talk to experts,

177
00:09:53,163 --> 00:09:54,617
we learn from our mistakes,

178
00:09:54,641 --> 00:09:56,140
we update our knowledge,

179
00:09:56,164 --> 00:09:58,130
we just keep getting better.

180
00:09:58,655 --> 00:10:00,611
But when it comes to being a good person,

181
00:10:00,635 --> 00:10:03,127
we think it's something we're just supposed to know,

182
00:10:03,151 --> 00:10:04,414
we're just supposed to do,

183
00:10:04,438 --> 00:10:07,746
without the benefit of effort or growth.

184
00:10:07,770 --> 00:10:09,610
So what I've been thinking about

185
00:10:09,634 --> 00:10:13,786
is what if we were to just forget about being good people,

186
00:10:13,810 --> 00:10:15,575
just let it go,

187
00:10:15,599 --> 00:10:18,695
and instead, set a higher standard,

188
00:10:18,719 --> 00:10:21,781
a higher standard of being a good-ish person?

189
00:10:24,711 --> 00:10:28,934
A good-ish person absolutely still makes mistakes.

190
00:10:28,958 --> 00:10:32,000
As a good-ish person, I'm making them all the time.

191
00:10:32,701 --> 00:10:37,075
But as a good-ish person, I'm trying to learn from them, own them.

192
00:10:37,099 --> 00:10:40,658
I expect them and I go after them.

193
00:10:40,682 --> 00:10:43,286
I understand there are costs to these mistakes.

194
00:10:43,310 --> 00:10:47,378
When it comes to issues like ethics and bias and diversity and inclusion,

195
00:10:47,402 --> 00:10:50,544
there are real costs to real people,

196
00:10:50,568 --> 00:10:51,883
and I accept that.

197
00:10:54,422 --> 00:10:56,303
As a good-ish person, in fact,

198
00:10:56,327 --> 00:10:59,010
I become better at noticing my own mistakes.

199
00:10:59,034 --> 00:11:01,334
I don't wait for people to point them out.

200
00:11:01,358 --> 00:11:03,500
I practice finding them,

201
00:11:03,524 --> 00:11:04,800
and as a result ...

202
00:11:05,731 --> 00:11:09,348
Sure, sometimes it can be embarrassing,

203
00:11:09,372 --> 00:11:11,234
it can be uncomfortable.

204
00:11:11,258 --> 00:11:14,604
We put ourselves in a vulnerable place, sometimes.

205
00:11:15,788 --> 00:11:17,939
But through all that vulnerability,

206
00:11:17,963 --> 00:11:22,303
just like in everything else we've tried to ever get better at,

207
00:11:22,327 --> 00:11:23,629
we see progress.

208
00:11:23,653 --> 00:11:24,804
We see growth.

209
00:11:24,828 --> 00:11:27,757
We allow ourselves to get better.

210
00:11:28,836 --> 00:11:32,257
Why wouldn't we give ourselves that?

211
00:11:32,764 --> 00:11:37,291
In every other part of our lives, we give ourselves room to grow --

212
00:11:37,315 --> 00:11:39,846
except in this one, where it matters most.

213
00:11:41,076 --> 00:11:42,227
Thank you.

214
00:11:42,251 --> 00:11:46,851
(Applause)

